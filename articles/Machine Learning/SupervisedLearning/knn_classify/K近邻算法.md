K近邻算法(kNN)
---------

简单的说，k-近邻算法采用测量不同特征值之间的距离的方式进行**分类**

优点：精度高、对异常值不敏感、无数据输入假定。
缺点：计算复杂度高、空间复杂度高。
适用数据范围：数值型和标称型。


### 原理

存在一个样本数据集合，样本数据集合中包含数据和标签(可以理解为数据对应的结果), 所以我们知道每一条数据与它的标签的对应关系。
当输入没有标签的新数据后，将新数据的每个特征和样本数据集中的数据的特征进行比较，然后提取样本集中与未知标签最相似(最近邻)的分类标签。
一般来说，我们只选取样本集中前k(通常不会大于20)个最佳匹配，这就是k-最近邻算法中的k的出处。然后在k个标签中出现次数最多的分类，
将作为这个新数据的分类(标签)


```python

```