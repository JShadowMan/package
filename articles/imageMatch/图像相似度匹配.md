图像相似度匹配
--------------

在大量图片中查找相同的或者说相似到肉眼已经看不出来差别的两张图片是非常困难的，
因为随着图片数量的增多，所需要对比的次数会以平方的复杂度增长。
所以这就需要计算机来帮忙进行识别了，一方面是因为计算机的处理速度，另一方面是因为计算机能以像素为单位进行对比。

如果需要进行图片相似度计算，那首先是对这些图片去重，即先把完全一致的图片排除掉，再对剩余图片进行相似度计算。
这样就可以减少因为重复计算导致的效率问题。所以我们可以先排除完全一致的图片(可以使用md5, sha1等方法)，然后再通过几种方法(直方图，感知哈希算法，SIFT)进行相似度匹配

> 所有的代码都可以在 http://192.168.1.251:4399/shadowman/ImageMatching 里得到
>
> 并且编译了扩展模块的 opencv 包也可以在这个仓库内下载

#### 直方图(histogram)

现实生活中的例子，我们会怎么描述一个人呢：这个人是国字脸，浓眉，大眼睛等等，
这就是这个人的特征，如果另一个人的特征和这个人特征基本一致，那我们可以说这两个人长的很像。对于图片来说也是如此。

对于图像来说，常见的图像特征有颜色特征，纹理特征，形状特征，空间特征等等。其中颜色特征算是最常用的了。
颜色特征又可以分为直方图，颜色集，颜色矩等。理论上不同图片的直方图都肯定是不一样的，所以可以将其称之为图像的指纹。

直方图能够描述一张图片中颜色的**全局分布**，如果说两张图片的颜色分布基本一致，或者说差值非常的小，
那我们就可以说这两张图是相似的。


以下是通过`Pillow`库获取图像直方图的例子
```python
# 在 Python 中最流行的的图像处理库非 Pillow 莫属了
# (Pillow 是 PIL 库的一个分支，只是比原始的PIL实现了更多的功能)
from PIL import Image

# 所以我们直接通过 Pillow 载入图片
image = Image.open(picture_path)

# Pillow 库中自带了计算直方图的方法，所以我们可以很方便的得到一张图片的直方图
hist = image.histogram()
```

**以下是展示的直方图是通过OpenCV来获取的，因为PIL中计算得到的直方图数据是原始数据，并没有进行通道分离**

![二哈直方图](https://raw.githubusercontent.com/JShadowMan/packages/master/articles/imageMatch/97a32fca2d4e9389d0e4025006b96686.png)

现在我们已经知道怎么得到一张图片的直方图了，所以接下来最主要的就是怎么计算两张图片的直方图的差异。
计算差异都多种办法，以下仅列举两种常见的计算差异的方法

第一种计算差异的方法通过数学解释：
![第一种计算差异的方法](https://raw.githubusercontent.com/JShadowMan/packages/master/articles/imageMatch/714b27b324124880aabc310447016327.png)

第二种计算差异的方法通过数学解释：
![第二种计算差异的方法](https://raw.githubusercontent.com/JShadowMan/packages/master/articles/imageMatch/8761d42de0348e350e43ddae91ba81e7.png)

```python
# 第一种为计算不同的地方占多少
def _compare_1(h1, h2):
    return math.sqrt(
        reduce(
            operator.add,
            list(
                map(
                    lambda a, b: (a - b) ** 2, h1, h2
                )
            )
        ) / len(h1)
    )
# 第二种方法计算相同的地方占多少
def _compare_2(h1, h2):
    return reduce(
        operator.add
        list(
            map(
                lambda a, b: 1 - abs(a - b) / max(a, b), h1, h2
            )
        )
    ) / len(h1)
```
所以我们来找两张类似点的图片，看看实际上的直方图是什么样的

上面的图片对应的是蓝色的线，下面的图片对应的是绿色的线
![对比](https://raw.githubusercontent.com/JShadowMan/packages/master/articles/imageMatch/4e323d33d409f2521cefb8f6aed72e76.png)

注意：这里有个问题，因为直方图是颜色的**全局分布**,所以在一些情况下，会出现因为颜色全局分布一致，
但是实际上并不是相似的图片的情况。如下例子，两张图片是完全不一样的，只不过因为两张图片上部都是山，
下部都是溪流，颜色基本一致，所以得到的直方图差距很小。

![相同的图片](https://raw.githubusercontent.com/JShadowMan/packages/master/articles/imageMatch/7145fc5d7e65299f390942b93b0e8f11.png)

在这种情况下，程序可能会认为这两张图片是相似的。现实显然不是，所以就需要通过对图像进行分块，
对于每一个分块单独进行直方图的相似度计算，最后统计所有的分块计算结果，在这种情况下，就可以显著的降低误差。

对图片进行分割的实现如下：
```python
def split_image(img, chunk_size = (64, 64)):
    # 图片总的宽度和高度
    w, h = img.size
    # 分割出小区块的宽度和高度
    _cw, _ch = part_size
    # 确保这张图片能被完整的分割
    assert w % _cw == 0 % _ch == 0
    # 返回每个区块的图像
    return [
        img.crop((i, j, i + _cw, j + _ch)).copy() for i in range(0, w, _cw) for j in range(0, h, _ch)
    ]
```

**总结**：使用局部颜色分布的直方图来进行相似度对比
 * 优点：计算简单，计算速度快，计算结果为浮点数，对比简单，结果较较准确
 * 缺点：一次只能进行2张图片的对比，图片数量较大时，对比次数会呈平方数增长，且区块越多，需要对比的次数越多

#### 感知哈希算法(Perceptual hash algorithm / PHA)

对比一张图片是否相似，最容易想到的方法是什么，很多人想到的第一个方法就是一个像素一个像素进行对比，
最后计算差值，满足一定条件就可以认为是相似的。感知哈希算法就是基于这个来实现的高准确度的算法。

感知哈希算法有两种形式，一种为采用DCT(离散余弦变换)的pHash，一种是采用渐变的方法计算差异的dHash。
为了计算简单，所以选用第二种方法来计算相似度。

这个算法的步骤如下：
 1. 缩小图片到9*8像素，即一行9个像素，一共8行。这是为了去除不必要的细节，只保留明暗和颜色信息
  > 这里我们通过 Pillow 的 resize 方法进行图像的缩放

 2. 将图片转化为灰度图（可以在PIL打开模式中选择灰度模式）
  > 具体的换算方法为：`Gray = (R * 30 + G * 59 + B * 11 + 50) / 100`

 3. 计算差异：每个相邻像素进行对比，如果前面的像素比后面的像素亮，记为1，否则记为0
  > 通过 getdata() 方法获取图像的所有像素信息

 4. 每行9个像素，就可以得到8个差异值，一共8行，所以可以得到一个64位的值。这个64位的值就是这张图片的指纹。
  > 通过两重循环一次读取8个差异，一共读取8次得到指纹

 5. 通过**汉明距离**来计算两张图片的差异。

##### 汉明距离
所谓汉明距离就是对于给定的两个值，计算需要变换多少步可以得到两个一样的值。如下例子

 * `1010`和`1110`的汉明距离为1，因为只要将`1010`的第二位变换为1就可以得到`1110`
 * `0000`和`1111`的汉明距离为4，因为每个位都不一样

所以对于一个64位的值，最简单的方法就是将这个0101的序列转化为long类型，然后计算异或的结果中有多少个1就可以了。当然，逐位进行对比也是没问题的。
```python
a = '010110010010010011'
b = '101011001010110011'

s = bin(int(a, 2) ^ int(b, 2)).count('1')
```

对于这个计算指纹的算法，具体实现如下
```python
# 通过 Pillow 读取这个图像
image = Image.open(image_path)
# 缩小这个图片到9*8像素
small_image = image.resize((resize_width, resize_height))
# 转化为灰度显示的图
grayscale_image = small_image.convert('L')
# 获取灰度图的像素值
pixels = list(grayscale_image.getdata())
# 储存计算结果
difference = []
# 一共对比8次(高度为8个像素)
for row in range(resize_height):
    # 每一行像素的起始索引
    row_start_index = row * resize_width    
    # 遍历当前行中的每一列
    for col in range(resize_width - 1):        
        # 当前像素的索引
        left_pixel_index = row_start_index + col
        # 计算图片指纹
        difference.append(pixels[left_pixel_index] > pixels[left_pixel_index + 1])
# 获取数字形式的指纹
fingerprints = int(''.join(difference), 2)
```

对于这个算法，精确度是要比直方图的要来得高，但是存在一个明显的缺点就是缩小图片到9*8像素之后，
**原始图片的细节全部丢失**，如果需要判断的是一些只有微小细节有出入的图片时，这个算法的精确度就不能满足要求了。

改进的方法也很简单，就是不缩放图片，直接使用原始图片大小进行计算汉明距离，但是，问题也会随之而来，
就是计算量会变得非常大，一张300*300像素的图片的指纹有299*300=89700位，这么长的指纹储存起都非常费劲。

#### 特征点匹配(Scale-invariant feature transform / SIFT)

特征点匹配是一种检测局部特征的算法，这些算法通过求一张图像中的特征点及其相关的尺度和方向的描述来得到特征。
换言之，通过一张图片中的矢量特征进行图像匹配可以获得良好的效果。
这几种图像匹配算法在opencv的扩展库中都有提供，我们就挑选其中的SIFT来讲，对于其他的算法，只需要替换算法实例就行。

SIFT特征不只具有尺度不变性，即使改变旋转角度，图像亮度或拍摄视角，仍然能够得到好的检测效果

> 图像匹配：图像匹配主要用于将 **不同时间、不同传感器、不同视角及不同拍摄条件下** 获取的两幅或多幅图像进行匹配
>
> 相似度检测：对于给定的两张图片，要求只有很细微的差别，细微到将这两张图片做快速切换也看不出差别，
> 即：要求这张图片的内容在空间位置，尺度，亮度等特征上要基本甚至说完全一致。
>
> 换言之，图像相似度检测和图像匹配还是有较大区别的。对于一张原始图片和一张旋转了180度的图片，
> 通过图像匹配可以通过检测图像内容特征点的的方式来判断两种图片所表达的是否是同一个内容，
> 而不关心图像内容的空间位置, 亮度，视角，尺度等信息。
>
> 而实际上，这两张互相颠倒的图片是不相似的，甚至可以说完全不一样。
>
> 简单的一个例子：现在有两张照片，一张是一个人在草地上的照片，另外一张是这个人在大学时照的合影。
> 所以在这种情况下，这两张图片必然是不同的，更不用说是相似了，但是在图像匹配的概念上，
> 这两张图片是有部分特征是可以匹配上的，匹配上的特征就是这个人的脸，这是图像匹配的特征决定的。

虽然这两者在概念上有所出入，但是还是有重叠的部分的。**图像匹配的范围大于相似度匹配**，
这就意味着可以人为缩小图像匹配作用的范围以达到同样的目的。即：通过**达到完美匹配的特征点数目占两张图片特征点总数的平均数的比例**来判断两张图片是否相似。

> OpenCV是一个基于BSD许可（开源）发行的跨平台计算机视觉库，可以运行在Linux、Windows、Android和Mac OS操作系统上。
> 它轻量级而且高效——由一系列 C 函数和少量 C++ 类构成，同时提供了Python、Ruby、MATLAB等语言的接口，
> 实现了图像处理和计算机视觉方面的很多通用算法。主要有以下用途：
>
> * 图像处理
> * 特征检测与描述
> * 视频分析
> * 相机校准与3D重建
> * 机器学习
> * 图像计算等等

对于我们的主题，用到的就是 **特征检测与描述** 这个部分的内容, 常见的的特征点匹配算法有`SIFT`, `SURF`, `FAST`, `ORB`。对于这几种方法，如果需要自己手动实现这些算法，那实在是个大工程。所以我们就通过编译附带了扩展模块的opencv直接使用这几种特征点算法。



我们首先看看SIFT
```python
import cv2

# 创建 SIFT 算法实例
sift = cv2.xfeatures2d.SIFT_create()

# 通过 opencv 以灰度模式读取图片
image1 = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
# 通过 opencv 得到特征点，并计算矢量信息等
kp = sift.detect(image1, None)
# 画出所有特征点
kp_img = cv2.drawKeypoints(image1, kp, None)

cv2.imshow('key-pointes', kp_img)
cv2.waitKey(0)
cv2.destroyAllWindows()
```
来看看效果

![meizi](https://raw.githubusercontent.com/JShadowMan/packages/master/articles/imageMatch/cd153aa780a206952a54899aed6a5957.png)

那么其他算法和SIFT有什么区别么，我们来看看对比测试
```python
# 创建 SIFT 算法实例
sift = cv2.xfeatures2d.SIFT_create()
# 创建 SURF 算法实例
surf = cv2.xfeatures2d.SURF_create()
# ORB 算法实例
orb = cv2.ORB_create()
# FAST 算法实例
fast = cv2.FastFeatureDetector_create()

kp1 = sift.detect(image1, None)
kp2 = surf.detect(image1, None)
kp3 = orb.detect(image1, None)
kp4 = fast.detect(image1, None)

sift_img = cv2.drawKeypoints(image1, kp1, None)
surf_img = cv2.drawKeypoints(image1, kp2, None)
orb_img = cv2.drawKeypoints(image1, kp3, None)
fast_img = cv2.drawKeypoints(image1, kp4, None)

# 显示图片省略
```
![对比](https://raw.githubusercontent.com/JShadowMan/packages/master/articles/imageMatch/5d3da7126276cb4188ebee526f0ea3fb.png)

显而易见：因为各个算法的计算特征点的实现方法不同，所以得到的特征点和计算速度上会存在差异。
所以具体使用哪种算法应该在做个测试之后在进行选择。


回到主题，以下是通过SIFT查找特征点然后通过暴力匹配的方式得到是否相似的具体实现

```python
boundary_value = .85

# 创建SIFT实例
sift = cv2.xfeatures2d.SIFT_create()

# 通过 opencv 读取文件
image1 = cv2.imread(image_1_path)
image2 = cv2.imread(image_2_path)
# 通过 opencv 得到特征点，并计算矢量信息等
kp1, des1 = sift.detectAndCompute(image1, None)
kp2, des2 = sift.detectAndCompute(image2, None)

# 采用匹配的特征点数目占平均特征点数目的比例来判断是否相似
bf = cv2.BFMatcher()
# knn(k最近邻)匹配算法
matches = bf.knnMatch(des1, des2, k=2)

# 最佳匹配的数目
good_match = 0
# 遍历每个匹配项以查找最佳匹配
for m, n in matches:
    # 获取与A距离最近的点B(最近)和C(次近)，只有当B/C小于阈值时(0.75)才被认为是匹配
    if m.distance < 0.75 * n.distance:
        good_match += 1
# 计算最佳匹配数目是否满足边界值
if good_match / (sum([len(kp1), len(kp2)]) / 2) >= boundary_value:
    pass
```

看看两张完全一样的图片（其中一张进过左右翻转+旋转90度）的特征点匹配结果

![rst](https://raw.githubusercontent.com/JShadowMan/packages/master/articles/imageMatch/aba57172be28b42cfac0ebf443ac2286.png)

可以在结果中证明以上结论：特征点匹配具有尺度不变性，可见不变性等。
**在用于相似度检测上有一定的局限性**。

#### 总结

在计算速度上：**直方图 > 特征点检测 >> 感知哈希算法**

在计算所使用的内存上：864张600*600像素前提
 * 直方图：30M
 * 特征点检测：120M
 * 感知哈希算法：300M(600 * 600), 60M(200 * 200)

环境配置/依赖上：
 * 直方图：需要 Pillow 模块
 * 感知哈希算法：需要 Pillow 模块
 * 特征点检测：需要自行编译带有 extra_contrib 的 opencv2 库，官方的 opencv2 并不带有 SIFT 算法。

所以在通常情况下可以把直方图作为第一选择，将特征点检测(具有局限性)作为第二选择，其次可以选择感知哈希算法。
